{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHZ8HkunnhBc"
      },
      "outputs": [],
      "source": [
        "!pip install gdown\n",
        "\n",
        "import gdown\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Download both files\n",
        "train_id = \"1ZR4cnzoT4TA9uH8xeA4Pk_0jGZtBtciN\"\n",
        "test_id = \"1Xt9wsLd2mWRONLjzT2wNdRIaFkVS_6q3\"\n",
        "\n",
        "gdown.download(f\"https://drive.google.com/uc?id={train_id}\", \"UNSW_FEIIDS_train.csv\", quiet=False)\n",
        "gdown.download(f\"https://drive.google.com/uc?id={test_id}\", \"UNSW_FEIIDS_test.csv\", quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAlqsq8M4lTE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "\n",
        "\n",
        "# =====================================================================\n",
        "# GPU OPTIMIZATION SETTINGS\n",
        "# =====================================================================\n",
        "# Enable memory growth to prevent OOM errors\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(f\"GPU memory growth enabled for {len(gpus)} GPU(s)\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "# Enable XLA (Accelerated Linear Algebra) for faster computations\n",
        "tf.config.optimizer.set_jit(True)\n",
        "\n",
        "# Enable mixed precision for faster training on modern GPUs\n",
        "from tensorflow.keras import mixed_precision\n",
        "if gpus:\n",
        "    policy = mixed_precision.Policy('mixed_float16')\n",
        "    mixed_precision.set_global_policy(policy)\n",
        "    print('Mixed precision enabled: Compute dtype=%s, variable dtype=%s' %\n",
        "          (policy.compute_dtype, policy.variable_dtype))\n",
        "\n",
        "# Disable unnecessary logging\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "# =====================================================================\n",
        "\n",
        "\n",
        "# Create folders for saving plots and models\n",
        "PLOTS_FOLDER = \"bilstm_plots\"\n",
        "MODELS_FOLDER = \"bilstm_models\"\n",
        "os.makedirs(PLOTS_FOLDER, exist_ok=True)\n",
        "os.makedirs(MODELS_FOLDER, exist_ok=True)\n",
        "\n",
        "\n",
        "# Detect runtime environment\n",
        "def get_runtime_environment():\n",
        "    try:\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "        tf.config.experimental_connect_to_cluster(tpu)\n",
        "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "        strategy = tf.distribute.TPUStrategy(tpu)\n",
        "        return \"TPU\", strategy\n",
        "    except:\n",
        "        gpus = tf.config.list_physical_devices('GPU')\n",
        "        if gpus:\n",
        "            return \"GPU\", tf.distribute.OneDeviceStrategy(\"/gpu:0\")\n",
        "        else:\n",
        "            return \"CPU\", tf.distribute.OneDeviceStrategy(\"/cpu:0\")\n",
        "\n",
        "\n",
        "# Optimized callback - evaluate less frequently to reduce overhead\n",
        "class TestEvaluationCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, test_data, eval_every=10):\n",
        "        super().__init__()\n",
        "        self.test_data = test_data\n",
        "        self.test_loss = []\n",
        "        self.test_accuracy = []\n",
        "        self.eval_every = eval_every\n",
        "        self.epoch_nums = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Only evaluate every N epochs to reduce overhead\n",
        "        if (epoch + 1) % self.eval_every == 0 or epoch == 0 or (epoch + 1) == 200:\n",
        "            X_test, y_test = self.test_data\n",
        "            test_loss, test_acc = self.model.evaluate(X_test, y_test, verbose=0)\n",
        "            self.test_loss.append(test_loss)\n",
        "            self.test_accuracy.append(test_acc)\n",
        "            self.epoch_nums.append(epoch + 1)\n",
        "\n",
        "\n",
        "def plot_training_history(history, test_callback, environment, hidden_nodes, save_folder):\n",
        "    \"\"\"Plot and save training history for accuracy and loss using test set as validation\"\"\"\n",
        "    all_epochs = range(1, len(history.history['accuracy']) + 1)\n",
        "\n",
        "    # Plot Accuracy\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(all_epochs, history.history['accuracy'], 'b-', label='Training Accuracy', linewidth=2, alpha=0.7)\n",
        "    plt.plot(test_callback.epoch_nums, test_callback.test_accuracy, 'ro-', label='Validation Accuracy',\n",
        "             linewidth=2, markersize=4)\n",
        "    plt.title(f'BiLSTM Training & Validation Accuracy\\n{environment} - {hidden_nodes} Hidden Nodes',\n",
        "              fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Epoch', fontsize=12)\n",
        "    plt.ylabel('Accuracy', fontsize=12)\n",
        "    plt.legend(fontsize=11)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    acc_filename = os.path.join(save_folder, f\"{environment}_{hidden_nodes}_acc.png\")\n",
        "    plt.savefig(acc_filename, dpi=150)\n",
        "    plt.close()\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(all_epochs, history.history['loss'], 'b-', label='Training Loss', linewidth=2, alpha=0.7)\n",
        "    plt.plot(test_callback.epoch_nums, test_callback.test_loss, 'ro-', label='Validation Loss',\n",
        "             linewidth=2, markersize=4)\n",
        "    plt.title(f'BiLSTM Training & Validation Loss\\n{environment} - {hidden_nodes} Hidden Nodes',\n",
        "              fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Epoch', fontsize=12)\n",
        "    plt.ylabel('Loss', fontsize=12)\n",
        "    plt.legend(fontsize=11)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    loss_filename = os.path.join(save_folder, f\"{environment}_{hidden_nodes}_loss.png\")\n",
        "    plt.savefig(loss_filename, dpi=150)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# =====================================================================\n",
        "# CONFIGURATION - CHANGE THIS FOR EACH RUN\n",
        "# =====================================================================\n",
        "HIDDEN_NODES = 40  # Change to: 10, 20, 30, 40, 50, 60, 70, 80\n",
        "# =====================================================================\n",
        "\n",
        "ENVIRONMENT, strategy = get_runtime_environment()\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"Running on: {ENVIRONMENT}\")\n",
        "print(f\"Hidden Nodes: {HIDDEN_NODES}\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "\n",
        "# Load normalized data\n",
        "print(\"Loading data...\")\n",
        "train_df = pd.read_csv(\"UNSW_FEIIDS_train.csv\")\n",
        "test_df = pd.read_csv(\"UNSW_FEIIDS_test.csv\")\n",
        "\n",
        "\n",
        "# Identify and separate labels\n",
        "label_cols = ['attack_cat', 'binary_label', 'Label', 'label']\n",
        "existing_labels = [col for col in label_cols if col in train_df.columns]\n",
        "\n",
        "\n",
        "X_full = train_df.drop(columns=existing_labels, errors='ignore').values\n",
        "y_full = train_df['binary_label'].values if 'binary_label' in train_df.columns else train_df['label'].values\n",
        "X_test_full = test_df.drop(columns=existing_labels, errors='ignore').values\n",
        "y_test_full = test_df['binary_label'].values if 'binary_label' in test_df.columns else test_df['label'].values\n",
        "\n",
        "\n",
        "print(f\"Dataset: {len(X_full):,} train | {len(X_test_full):,} test | {X_full.shape[1]} features\")\n",
        "\n",
        "\n",
        "# Sample 14,000 for training and 3,500 for testing (as per Table 6)\n",
        "np.random.seed(42)\n",
        "train_indices = np.random.choice(len(X_full), 14000, replace=False)\n",
        "test_indices = np.random.choice(len(X_test_full), 3500, replace=False)\n",
        "\n",
        "\n",
        "# Create train and test sets\n",
        "X_train = X_full[train_indices]\n",
        "y_train = y_full[train_indices]\n",
        "X_test = X_test_full[test_indices]\n",
        "y_test = y_test_full[test_indices]\n",
        "\n",
        "\n",
        "# Reshape for LSTM: (samples, timesteps=1, features)\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
        "\n",
        "\n",
        "# Convert to float32 for better GPU performance\n",
        "X_train = X_train.astype('float32')\n",
        "y_train = y_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "y_test = y_test.astype('float32')\n",
        "\n",
        "print(f\"Prepared: {X_train.shape[0]:,} train | {X_test.shape[0]:,} test\\n\")\n",
        "\n",
        "\n",
        "# Configuration - OPTIMIZED FOR GPU\n",
        "EPOCHS = 200\n",
        "BATCH_SIZE = 128  # Increased from 64 to better utilize GPU\n",
        "results_file = \"bilstm_table_results.csv\"\n",
        "\n",
        "\n",
        "# Train single model\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Training BiLSTM with {HIDDEN_NODES} hidden nodes on {ENVIRONMENT}\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "with strategy.scope():\n",
        "    # Build BiLSTM model (2 layers as per paper)\n",
        "    model = Sequential([\n",
        "        Bidirectional(LSTM(HIDDEN_NODES,\n",
        "                          return_sequences=True,\n",
        "                          activation='tanh',  # Explicit for CuDNN\n",
        "                          recurrent_activation='sigmoid'),  # Explicit for CuDNN\n",
        "                     input_shape=(1, X_train.shape[2])),\n",
        "        Bidirectional(LSTM(HIDDEN_NODES,\n",
        "                          return_sequences=False,\n",
        "                          activation='tanh',\n",
        "                          recurrent_activation='sigmoid')),\n",
        "        Dense(1, activation='sigmoid', dtype='float32')  # Explicit output dtype\n",
        "    ])\n",
        "\n",
        "    # Use Adam with slightly higher learning rate for faster convergence\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "print(\"Model built. Starting training...\\n\")\n",
        "\n",
        "# Create optimized callback (evaluate every 10 epochs instead of every epoch)\n",
        "test_callback = TestEvaluationCallback((X_test, y_test), eval_every=10)\n",
        "\n",
        "# Create TensorFlow dataset for better GPU utilization\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)\n",
        "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)  # Prefetch for GPU\n",
        "\n",
        "# Train model\n",
        "start_train = time.time()\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    verbose=2,  # Less verbose output\n",
        "    callbacks=[test_callback],\n",
        "    steps_per_epoch=len(X_train) // BATCH_SIZE\n",
        ")\n",
        "train_time = time.time() - start_train\n",
        "\n",
        "# Plot training history\n",
        "print(f\"\\nGenerating plots for {HIDDEN_NODES} hidden nodes...\")\n",
        "plot_training_history(history, test_callback, ENVIRONMENT, HIDDEN_NODES, PLOTS_FOLDER)\n",
        "print(\"âœ“ Plots saved\\n\")\n",
        "\n",
        "# Test model (final evaluation)\n",
        "start_test = time.time()\n",
        "y_pred_proba = model.predict(X_test, batch_size=BATCH_SIZE, verbose=0)\n",
        "test_time = time.time() - start_test\n",
        "\n",
        "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "test_loss = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE, verbose=0)[0]\n",
        "\n",
        "# Store result\n",
        "result = {\n",
        "    'Environment': ENVIRONMENT,\n",
        "    'Hidden_Nodes': HIDDEN_NODES,\n",
        "    'Accuracy': round(accuracy, 4),\n",
        "    'Train_Time': round(train_time, 2),\n",
        "    'Test_Time': round(test_time, 2),\n",
        "    'Test_Loss': round(test_loss, 4)\n",
        "}\n",
        "\n",
        "# Save model\n",
        "model_filename = os.path.join(MODELS_FOLDER, f\"bilstm_{ENVIRONMENT}_{HIDDEN_NODES}nodes.keras\")\n",
        "model.save(model_filename)\n",
        "print(f\"Model saved: {model_filename}\\n\")\n",
        "\n",
        "# Save to CSV\n",
        "result_df = pd.DataFrame([result])\n",
        "if os.path.exists(results_file):\n",
        "    existing_df = pd.read_csv(results_file)\n",
        "    combined_df = pd.concat([existing_df, result_df], ignore_index=True)\n",
        "    combined_df.to_csv(results_file, index=False)\n",
        "else:\n",
        "    result_df.to_csv(results_file, index=False)\n",
        "\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"RESULTS for {HIDDEN_NODES} hidden nodes:\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
        "print(f\"Train Time: {train_time:.2f}s\")\n",
        "print(f\"Test Time: {test_time:.2f}s\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"\\nSaved to: {results_file}\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "# Display current results\n",
        "if os.path.exists(results_file):\n",
        "    final_results = pd.read_csv(results_file)\n",
        "    print(\"All Results So Far:\")\n",
        "    print(final_results)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
